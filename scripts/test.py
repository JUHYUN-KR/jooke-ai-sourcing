#!/usr/bin/env python3
"""
Jooke Project í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì£¼ìš” ê¸°ëŠ¥ë“¤ì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
"""

import sys
import os
import json
import unittest
from unittest.mock import Mock, patch

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from ai_analysis.claude_analysis import ClaudeAnalyzer
from ai_analysis.gpt_analysis import GPTAnalyzer
from ai_analysis.cross_validation import CrossValidator
from automation.customer_service import CustomerService
from collaboration.field_research import FieldResearch
from dashboard.performance_tracker import PerformanceTracker

class TestJookeSystem(unittest.TestCase):
    """
    Jooke ì‹œìŠ¤í…œ ë©”ì¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    """
    
    def setUp(self):
        """
        í…ŒìŠ¤íŠ¸ ì„¤ì •
        """
        self.test_product_data = {
            'name': 'Test Omega-3 Fish Oil',
            'price_cad': 29.99,
            'brand': 'Test Brand',
            'category': 'ê±´ê°•ì‹í’ˆ',
            'description': 'High quality omega-3 supplement'
        }
        
        self.test_claude_result = {
            'timestamp': '2025-05-30T15:30:00',
            'analysis': 'Market potential: 8/10, Competition: 6/10',
            'status': 'success'
        }
        
        self.test_gpt_result = {
            'timestamp': '2025-05-30T15:35:00',
            'analysis': 'Expected margin: 65%, Korean price: 42000',
            'status': 'success'
        }
    
    @patch('ai_analysis.claude_analysis.Anthropic')
    def test_claude_analyzer(self, mock_anthropic):
        """
        Claude ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸
        """
        # Mock Claude API ì‘ë‹µ
        mock_client = Mock()
        mock_response = Mock()
        mock_response.content = [Mock(text='{
  "market_potential": 8,
  "competition_level": 6,
  "entry_score": 75
}')]
        mock_client.messages.create.return_value = mock_response
        mock_anthropic.return_value = mock_client
        
        analyzer = ClaudeAnalyzer()
        result = analyzer.analyze_product(self.test_product_data)
        
        self.assertEqual(result['status'], 'success')
        self.assertIn('analysis', result)
        self.assertIn('timestamp', result)
    
    @patch('ai_analysis.gpt_analysis.OpenAI')
    def test_gpt_analyzer(self, mock_openai):
        """
        GPT ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸
        """
        # Mock GPT API ì‘ë‹µ
        mock_client = Mock()
        mock_response = Mock()
        mock_response.choices = [Mock(message=Mock(content='{
  "expected_margin": 65,
  "korean_price": 42000
}'))]
        mock_client.chat.completions.create.return_value = mock_response
        mock_openai.return_value = mock_client
        
        analyzer = GPTAnalyzer()
        result = analyzer.calculate_margins(self.test_product_data)
        
        self.assertEqual(result['status'], 'success')
        self.assertIn('analysis', result)
        self.assertIn('timestamp', result)
    
    def test_cross_validator(self):
        """
        êµì°¨ ê²€ì¦ê¸° í…ŒìŠ¤íŠ¸
        """
        validator = CrossValidator()
        result = validator.validate_analysis(
            self.test_claude_result, 
            self.test_gpt_result
        )
        
        self.assertEqual(result['status'], 'success')
        self.assertIn('consistency_score', result)
        self.assertIn('final_score', result)
        self.assertIn('final_recommendation', result)
        
        # ì¼ì¹˜ë„ ì ìˆ˜ëŠ” 0-1 ì‚¬ì´
        self.assertGreaterEqual(result['consistency_score'], 0)
        self.assertLessEqual(result['consistency_score'], 1)
        
        # ìµœì¢… ì ìˆ˜ëŠ” 0-100 ì‚¬ì´
        self.assertGreaterEqual(result['final_score'], 0)
        self.assertLessEqual(result['final_score'], 100)
    
    def test_customer_service(self):
        """
        ê³ ê° ì„œë¹„ìŠ¤ ìë™í™” í…ŒìŠ¤íŠ¸
        """
        cs = CustomerService()
        
        # ë°°ì†¡ ë¬¸ì˜ í…ŒìŠ¤íŠ¸
        result = cs.classify_inquiry("ë°°ì†¡ì€ ì–¸ì œ ë˜ë‚˜ìš”?")
        self.assertEqual(result['category'], 'ë°°ì†¡')
        self.assertFalse(result['requires_human'])
        
        # í™˜ë¶ˆ ë¬¸ì˜ í…ŒìŠ¤íŠ¸
        result = cs.classify_inquiry("í™˜ë¶ˆ ë°›ê³  ì‹¶ì–´ìš”")
        self.assertEqual(result['category'], 'í™˜ë¶ˆ')
        
        # ê¸°íƒ€ ë¬¸ì˜ í…ŒìŠ¤íŠ¸
        result = cs.classify_inquiry("ì´ìƒí•œ ì§ˆë¬¸ì…ë‹ˆë‹¤")
        self.assertEqual(result['category'], 'ê¸°íƒ€')
        self.assertTrue(result['requires_human'])
    
    def test_field_research(self):
        """
        í˜„ì§€ ì¡°ì‚¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        """
        research = FieldResearch()
        
        test_data = {
            'product_name': 'Test Product',
            'store_location': 'Test Store, Toronto',
            'price_cad': 24.99,
            'quality_score': 4,
            'recommendation': 'ì¶”ì²œ'
        }
        
        result = research.add_research_data(test_data)
        self.assertEqual(result['status'], 'success')
        self.assertIn('entry_id', result)
        
        # ìš”ì•½ ìƒì„± í…ŒìŠ¤íŠ¸
        summary = research.get_research_summary()
        self.assertIn('total_products', summary)
        self.assertIn('recommended', summary)
        self.assertEqual(summary['total_products'], 1)
    
    def test_performance_tracker(self):
        """
        ì„±ê³¼ ì¶”ì ê¸° í…ŒìŠ¤íŠ¸
        """
        tracker = PerformanceTracker()
        
        test_data = [
            {
                'timestamp': '2025-05-30T10:00:00',
                'product_name': 'Product 1',
                'category': 'ê±´ê°•ì‹í’ˆ',
                'margin_percent': 65,
                'recommendation': 'ì¶”ì²œ',
                'jaeho_opinion': 'ì¢‹ìŒ'
            },
            {
                'timestamp': '2025-05-30T11:00:00',
                'product_name': 'Product 2',
                'category': 'í«ìš©í’ˆ',
                'margin_percent': 45,
                'recommendation': 'ë³´ë¥˜',
                'jaeho_opinion': ''
            }
        ]
        
        # KPI ê³„ì‚° í…ŒìŠ¤íŠ¸
        kpis = tracker.calculate_kpis(test_data)
        self.assertEqual(kpis['analysis_count'], 2)
        self.assertEqual(kpis['success_rate'], 50.0)  # 1/2 = 50%
        self.assertEqual(kpis['avg_margin'], 55.0)    # (65+45)/2 = 55%
        
        # ì£¼ê°„ ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸
        report = tracker.generate_weekly_report(test_data)
        self.assertIn('summary', report)
        self.assertIn('top_products', report)
        self.assertIn('insights', report)

class TestIntegration(unittest.TestCase):
    """
    í†µí•© í…ŒìŠ¤íŠ¸
    """
    
    def test_full_pipeline_mock(self):
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª© í…ŒìŠ¤íŠ¸
        """
        # ëª© ë°ì´í„°
        product_data = {
            'name': 'Test Product',
            'price_cad': 29.99,
            'category': 'ê±´ê°•ì‹í’ˆ'
        }
        
        claude_result = {
            'status': 'success',
            'analysis': 'Good product',
            'timestamp': '2025-05-30T15:30:00'
        }
        
        gpt_result = {
            'status': 'success', 
            'analysis': 'High margin',
            'timestamp': '2025-05-30T15:35:00'
        }
        
        # êµì°¨ ê²€ì¦
        validator = CrossValidator()
        validation_result = validator.validate_analysis(claude_result, gpt_result)
        
        # ê²°ê³¼ ê²€ì¦
        self.assertEqual(validation_result['status'], 'success')
        self.assertIn('final_recommendation', validation_result)
        
        recommendation = validation_result['final_recommendation']
        self.assertIn('decision', recommendation)
        self.assertIn('confidence', recommendation)
        self.assertIn('next_steps', recommendation)

def run_tests():
    """
    ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    """
    print("ğŸ§ª Jooke AI Sourcing í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    print("="*50)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
    suite.addTests(loader.loadTestsFromTestCase(TestJookeSystem))
    suite.addTests(loader.loadTestsFromTestCase(TestIntegration))
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*50)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*50)
    print(f"ğŸ“ ì „ì²´ í…ŒìŠ¤íŠ¸: {result.testsRun}ê°œ")
    print(f"âœ… ì„±ê³µ: {result.testsRun - len(result.failures) - len(result.errors)}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(result.failures)}ê°œ")
    print(f"ğŸ’¥ ì˜¤ë¥˜: {len(result.errors)}ê°œ")
    
    if result.failures:
        print("\nğŸ”´ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
        for test, traceback in result.failures:
            print(f"  - {test}")
    
    if result.errors:
        print("\nğŸ’¥ ì˜¤ë¥˜ê°€ ë°œìƒí•œ í…ŒìŠ¤íŠ¸:")
        for test, traceback in result.errors:
            print(f"  - {test}")
    
    # ì „ì²´ ì„±ê³µ ì—¬ë¶€
    if result.wasSuccessful():
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
    else:
        print("\nğŸ˜¨ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return False

if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)